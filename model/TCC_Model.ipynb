{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "yBQo4QZVKPoq",
    "outputId": "93a99979-1957-428d-d9a5-a87963cb3e52"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "aTPwMU-xK57m",
    "outputId": "b1f914b7-3bec-4254-a2bf-63cabddc5514"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>id</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>set</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww  he matches this background colour i m s...</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on im...</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text                id  \\\n",
       "0  explanation why the edits made under my userna...  0000997932d777bf   \n",
       "1  d aww  he matches this background colour i m s...  000103f0d9cfb60f   \n",
       "2  hey man  i m really not trying to edit war  it...  000113f07ec002fd   \n",
       "3    more i can t make any real suggestions on im...  0001b41b1c6bb37e   \n",
       "4  you  sir  are my hero  any chance you remember...  0001d958c54c6e35   \n",
       "\n",
       "   identity_hate  insult  obscene    set  severe_toxic  threat  toxic  \\\n",
       "0            0.0     0.0      0.0  train           0.0     0.0    0.0   \n",
       "1            0.0     0.0      0.0  train           0.0     0.0    0.0   \n",
       "2            0.0     0.0      0.0  train           0.0     0.0    0.0   \n",
       "3            0.0     0.0      0.0  train           0.0     0.0    0.0   \n",
       "4            0.0     0.0      0.0  train           0.0     0.0    0.0   \n",
       "\n",
       "   toxicity  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LtRQRWB0NN2I"
   },
   "source": [
    "**A little description about the dataset**\n",
    "\n",
    "Value of column identtify_hate is 1 if a comment is hate comment.   \n",
    "Value of column insult is 1 if a comment is an insult.  \n",
    "Same for sever_toxic,threat,toxic.\n",
    "\n",
    "Also a comment can be classified into ***multiple classes*** at the same time, means a comment can be both hate and insult at the same time.  \n",
    "\n",
    "Column toxicity contains the ***number of classes*** to which a comment belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjBlDmkEK75J"
   },
   "outputs": [],
   "source": [
    "# Right now we are only interrested in finding if a comment is toxic or not so we extract only the comment col and toxicity col\n",
    "x = data[\"comment_text\"].values\n",
    "y = data[\"toxicity\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "X29O-gZtLYQW",
    "outputId": "2fbaf06d-97f7-4021-f420-a3c6a18d829f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    143346\n",
       "1.0      6360\n",
       "3.0      4209\n",
       "2.0      3480\n",
       "4.0      1760\n",
       "5.0       385\n",
       "6.0        31\n",
       "Name: toxicity, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxicity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKkeTsp5PxGf"
   },
   "source": [
    "We are only interested in binary classification of comment into toxic or non toxic and a comment is toxic if its y value is greater than or equal to 1. \n",
    "\n",
    "So lets merge all the comments whose y >= 1 into one single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PgbV63NuPHk0",
    "outputId": "0bb60897-b389-4af2-f417-6239191941c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([143346,  16225], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y > 0] = 1\n",
    "np.unique(y,return_counts=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rIM7XZKVQpNs"
   },
   "source": [
    "Out of 159,571 comments in the dataset 143346 belong to non toxic class and 16225 belong to toxic class.\n",
    "\n",
    "Only 10% of the comments belong to toxic class. Clearly our dataset is **heavily imbalanced.**\n",
    "\n",
    "This problem of imbalance dataset can be dealt in a better way but right now we decide to deal with this by **randomly selecting** 30000 comments from non toxic class and then merging them with toxic class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skIq_bmlQmk5"
   },
   "outputs": [],
   "source": [
    "# First filtering comments into non_toxic and toxic class.\n",
    "non_toxic = x[y==0]\n",
    "toxic = x[y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "27UKjgmtTV55",
    "outputId": "eb0b45bd-b80b-4bed-a959-330f4123c266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,) (16225,)\n"
     ]
    }
   ],
   "source": [
    "# Randomly selecting 30000 non toxic comments.\n",
    "ids = np.arange(non_toxic.shape[0])\n",
    "np.random.shuffle(ids)\n",
    "ids = ids[:30000]\n",
    "\n",
    "non_toxic_selected = []\n",
    "\n",
    "for i in ids:\n",
    "    non_toxic_selected.append(non_toxic[i])\n",
    "\n",
    "non_toxic_selected = np.asarray(non_toxic_selected)\n",
    "print(non_toxic_selected.shape,toxic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "e_4MW4AvTmuw",
    "outputId": "3013b66b-c38c-41cc-b5c3-0b61f8ef0402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46225,)\n"
     ]
    }
   ],
   "source": [
    "# Merging non toxic and toxic comments into one array\n",
    "comments = np.concatenate((non_toxic_selected,toxic))\n",
    "print(comments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tuBBtmWtT4Wk"
   },
   "source": [
    "Now we have an array 'comments' which contains 46225 commennts. Out of which first 30000 comments are non toxic and rest 16225 comments are toxic.\n",
    "\n",
    "Percentage of toxic comments in our new dataset is 35%.\n",
    "\n",
    "We're gonna have to define our new y array i.e. target array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULLkfm5yTv5h"
   },
   "outputs": [],
   "source": [
    "y_new = np.zeros((46225,),dtype=\"int\")\n",
    "y_new[30000:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JNUw3tlUqhP"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5RUeaPlBUtKa"
   },
   "outputs": [],
   "source": [
    "class MEModelNB:\n",
    "\n",
    "  # We're gonna use Multinomial Event Model Naive Bayes for text classification.\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.N = 0 # Total Documents\n",
    "        self.Nc = [0,1] # List of all the classes\n",
    "        self.count_Nc = [0,0] # contains the count of all the documents belonging to a particular class\n",
    "        self.vocab = {}  # contains the vocab \n",
    "        self.V = 0 # total vocab size\n",
    "        self.count_w_c = {} # contains frequency of word in a particular class\n",
    "        self.count_c = [0,0] # contains total number of words occuring in the class by index\n",
    "        self.prior_prob = [] # contains the prior probability of all the classes\n",
    "\n",
    "    def commentPreProcessing(self,comment):\n",
    "    \n",
    "        \"\"\"This function performs text preprocessing i.e. it removes stopwords and does \n",
    "    \n",
    "        lemmatization and return all the useful words/tokens in the comment.\"\"\"\n",
    "     \n",
    "        comment = comment.lower()\n",
    "    \n",
    "        # Performing Tokenization\n",
    "        sentences = sent_tokenize(comment)\n",
    "    \n",
    "        words = []\n",
    "    \n",
    "        for sentence in sentences:\n",
    "            c_words = word_tokenize(sentence)\n",
    "        \n",
    "            for w in c_words:\n",
    "                if w not in words:\n",
    "                    words.append(w)\n",
    "    \n",
    "        # Performing Lemmatization and stopword removal.\n",
    "        words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "\n",
    "        return words\n",
    "\n",
    "\n",
    "    def train(self,comments,c_class):\n",
    "    \n",
    "        \"\"\" Accepts training data and trains the model. \"\"\"\n",
    "    \n",
    "        m = len(comments)\n",
    "        for i in range(m):\n",
    "      \n",
    "            comment = comments[i]\n",
    "            c = c_class[i]\n",
    "\n",
    "            # Step 1 - increment the count of total documents we have learned from N.\n",
    "            self.N = self.N + 1\n",
    "\n",
    "            # Step 2 - increment the count of documents that have been mapped to this category Nc.\n",
    "            self.count_Nc[c] = self.count_Nc[c] + 1\n",
    "\n",
    "            # Step 3 - Perform comment pre processing.\n",
    "            words = self.commentPreProcessing(comment)\n",
    "\n",
    "            # Step 4 - \n",
    "                #   4.1 if we encounter new words in this document, add them to our vocabulary,and update our vocabulary size |V|.\n",
    "                #   4.2 update count(w, c ) => the frequency with which each word in the document has been mapped to this category.\n",
    "                #   4.3 update count ( c ) => the total count of all words that have been mapped to this class.\n",
    "\n",
    "            for w in words:\n",
    "                if w in self.vocab:\n",
    "                    self.vocab[w] = self.vocab[w] + 1\n",
    "                    if(self.count_w_c[w][c] == 0):\n",
    "                        self.count_c[c] += 1\n",
    "          \n",
    "                    self.count_w_c[w][c] += 1\n",
    "                else:\n",
    "                    self.vocab[w] = 1\n",
    "                    self.count_w_c.setdefault(w,[0,0])\n",
    "                    self.count_w_c[w][c] = 1\n",
    "                    self.count_c[c] += 1\n",
    "                    self.V = self.V + 1\n",
    "    \n",
    "        # Step 5 - Calculate prior probability of both the classes.\n",
    "        for i in range(2): \n",
    "            prob = self.count_Nc[i]/float(self.N)\n",
    "            self.prior_prob.append(prob)\n",
    "\n",
    "\n",
    "    def predict(self,comment):\n",
    "    \n",
    "        \"\"\" This function accepts a comment and predicts whether it belongs to Toxic class or Non Toxic class.\"\"\"\n",
    "\n",
    "        # Step 1 - Peform comment pre processing.\n",
    "        words = self.commentPreProcessing(comment)\n",
    "    \n",
    "        likelihood = [1,1]\n",
    "    \n",
    "        # We need to iterate through each word in the document \n",
    "        # and calculate: P(w|c) = [count(w,c) + 1]/[count(c) + |V|]\n",
    "\n",
    "        # x = <w1,w2,w3....wn>, where x = comment whose class is to predicted\n",
    "        # P(x|c) = Product(P(wi|c)) , c = class which is either toxic or non toxic.\n",
    "    \n",
    "        # We multiply each P(w|c) for each word w in the new document, then multiply by P(c) (Prior probability of class c)\n",
    "        # and the result is the probability that this document belongs to this class.\n",
    "\n",
    "        for c in self.Nc:\n",
    "      \n",
    "            for w in words:\n",
    "                if w in self.vocab:\n",
    "                    cond = (self.count_w_c[w][c] + 1)/(self.count_c[c] + self.V)\n",
    "                else:\n",
    "                    cond = 1/(self.count_c[c] + self.V)\n",
    "          \n",
    "                likelihood[c] = likelihood[c] * cond\n",
    "            \n",
    "        for i in range(2):\n",
    "            likelihood[i] = likelihood[i] * self.prior_prob[i]\n",
    "\n",
    "        # Predict the class which has highest P(Y=C|x) posterior probabiliy.\n",
    "        pred = np.argmax(likelihood)\n",
    "    \n",
    "        if(pred == 1):\n",
    "            return \"Toxic\"\n",
    "        else:\n",
    "            return \"Non Toxic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPB75oN0Z7_k"
   },
   "outputs": [],
   "source": [
    "clf = MEModelNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bie7h3Agb6mM"
   },
   "outputs": [],
   "source": [
    "clf.train(comments,y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0vgtsW0cuAL"
   },
   "source": [
    "**Testing Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Y26SIR6ScmhF",
    "outputId": "6791d24c-ce43-4213-f444-e7d8a71014d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toxic'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict('can you please shut up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WE-2uzv6cpVr",
    "outputId": "96b33f86-3ab8-40e5-b022-ca0e005efa13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toxic'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict('shut up you shitty idiot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "urh77x12crS1",
    "outputId": "0ac334b8-9337-46e8-fccb-ffad83fcd4d3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toxic'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict('shut up you shitty idiot good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2PSZcXABc2Rm",
    "outputId": "cfff3522-c530-4ed4-b91c-22ea61749409"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toxic'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict('shut up you shitty idiot good nice thanks please')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BosY28d8fId5",
    "outputId": "cbf6f8c3-7a82-41d5-ef6f-90dd4e245e36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Non Toxic'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict('thanks a lot for explaining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rnWdD92pfNCw",
    "outputId": "143144c1-da36-4d6f-a842-25d63e66d3c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Non Toxic'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict('nice explaination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_fPU42kIfRTM",
    "outputId": "3690d076-d58b-4d96-f4b3-d91a681afacf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Non Toxic'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict('Hi! how are you?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19Siqn6CAMD3"
   },
   "source": [
    "**Building Confusion Matrix and calculating F1 Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzuCuifE_5Yc"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(comments, y_new, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocuFiRvRBVIf"
   },
   "outputs": [],
   "source": [
    "classifier2 = MEModelNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dF2gZ-naBeU2"
   },
   "outputs": [],
   "source": [
    "classifier2.train(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_3tLmOUBkH4"
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "count = 0\n",
    "for i in range(x_test.shape[0]):\n",
    "    pred = classifier2.predict(x_test[i])\n",
    "    if pred == \"Toxic\":\n",
    "        y_pred.append(1)\n",
    "    else:        \n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ejmsz2abCpND",
    "outputId": "33b68347-581a-4628-e83e-78962ad70b9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2312,) (2312,)\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.asarray(y_pred)\n",
    "print(y_test.shape,y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "qD3AasS7B5u2",
    "outputId": "c71fb588-5cb1-48eb-8d45-f842fc9dc1bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1476,   11],\n",
       "       [ 423,  402]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6Aq2W_SoGe6T",
    "outputId": "46f603fe-3d45-4bd2-8404-f275839554b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6494345718901454"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R5m0QSundByG"
   },
   "source": [
    "**Future work**\n",
    "\n",
    "Our model gives good prediction for sentences which contain toxic words but fails when it comes to sentences which do not contain toxic words but are still toxic.\n",
    "\n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FzLB01btc5Ta",
    "outputId": "f18aa541-4b62-497d-86bf-ff57f54962eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Non Toxic'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict('not my fault you lack brain cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7-5L7k4Nda_a",
    "outputId": "8296a801-33fa-473d-897a-619f314b61af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toxic'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict('not my fault you lack brain cells idiot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1OsxCLLqvpb4"
   },
   "source": [
    "**Let's Save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvQuOwYKddIQ"
   },
   "outputs": [],
   "source": [
    "model = open('model.pkl', 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88hJ41GcebHS"
   },
   "outputs": [],
   "source": [
    "pickle.dump(clf,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTA6C-Tof0_x"
   },
   "outputs": [],
   "source": [
    "model.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TCC Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
